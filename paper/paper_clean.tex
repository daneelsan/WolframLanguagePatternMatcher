\documentclass[10pt,twocolumn]{article}

% ============================================================================
% PACKAGES
% ============================================================================
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,calc}
\usepackage{booktabs}
\usepackage{geometry}
\usepackage{mmacells}
\usepackage{tikz}
\usetikzlibrary{trees, positioning, shapes}
\usepackage{forest}
\geometry{left=2cm,right=2cm,top=2.5cm,bottom=2.5cm}

% ============================================================================
% CODE LISTING CONFIGURATION
% ============================================================================
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{wolfram}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstdefinestyle{bytecode}{
    backgroundcolor=\color{backcolour},
    basicstyle=\ttfamily\small,
    breaklines=true,
    numbers=left,
    numberstyle=\tiny\color{codegray},
    showspaces=false,
    showstringspaces=false,
    tabsize=2
}

\lstset{style=wolfram}

% ============================================================================
% TITLE AND AUTHORS
% ============================================================================
\title{\textbf{A Virtual Machine for Wolfram Language Pattern Matching}}

\author{
Héctor Daniel Sanchez Domínguez\\
Pontificia Universidad Católica del Perú (PUCP)\\
\texttt{hdsanchez@pucp.edu.pe}
}

\date{}

% ============================================================================
% DOCUMENT
% ============================================================================
\begin{document}

\maketitle

% ============================================================================
% ABSTRACT
% ============================================================================
\begin{abstract}
Pattern matching is fundamental to symbolic computation in the Wolfram Language, yet its current implementation—based on recursive interpretive evaluation—limits the performance and analyzability of complex patterns. Alternatives, deep nesting, and user-defined predicates introduce high overhead under repeated evaluation and lead to opaque control flow and backtracking behavior.

This paper presents a register-based virtual machine that compiles Wolfram Language patterns into bytecode for efficient, predictable execution. The design uses a compact instruction set of 21 opcodes tailored to pattern-matching primitives and an explicit, structured backtracking mechanism. We outline the design rationale, instruction-set architecture, compilation strategy, and paclet interface, and show that complex patterns compile into small, analyzable programs with transparent control flow. The implementation is fully compatible with Wolfram's native `MatchQ` for all supported pattern constructs.
\end{abstract}

\noindent\textbf{Keywords:} Pattern matching, virtual machine, bytecode compilation, symbolic computation, Wolfram Language, backtracking, register-based architecture

% ============================================================================
% 1. INTRODUCTION
% ============================================================================
\section{Introduction}

Pattern matching in symbolic computation systems enables programs to identify, extract, and transform structured data based on declarative specifications. In Wolfram Language, pattern matching serves as the foundation for function definitions, rule-based transformations, and structural queries.

Consider a simple pattern match:
\begin{mmaCell}{Input}
MatchQ[f[5, 5], f[x_, x_]]
\end{mmaCell}
\begin{mmaCell}{Output}
True (* with x bound to 5 *)
\end{mmaCell}

This single operation encodes structural decomposition (checking head and argument count), variable binding (capturing the first argument), and constraint checking (verifying both arguments are equal). While simple cases execute efficiently, Wolfram Language's pattern matcher—implemented through recursive, interpreter-driven evaluation—becomes costly for complex patterns involving alternatives, deep nesting, or predicates. Moreover, its implicit control flow and backtracking semantics make execution difficult to trace, reason about, or optimize, especially in performance-critical workloads.

\subsection{Motivation}

The key observation is that \textbf{patterns are programs}: they describe computations that determine whether an input satisfies a structural or semantic specification. As with other programs, patterns benefit from being compiled rather than interpreted.

\begin{itemize}
    \item \textbf{Amortized cost}: compile once and execute efficiently across many inputs.
    \item \textbf{Explicit control flow}: replace implicit recursive traversal with direct jumps and structured backtracking.
    \item \textbf{Observability}: provide a transparent execution model that supports profiling, tracing, and instrumentation.
    \item \textbf{Portability}: compiled bytecode can be cached, serialized, inspected, or reused across sessions.
    \item \textbf{Optimizable representation}: compiled patterns enable separate optimization passes (e.g., dead-branch elimination, common-subpattern factoring) independent of their surface syntax.
\end{itemize}

Pattern compilation is especially advantageous in workloads such as:
\begin{itemize}
    \item repeated rule-based transformations applied to large data streams or expression sets,
    \item frequently invoked pattern-based function definitions in performance-sensitive code,
    \item large-scale pattern search, filtering, or classification across symbolic expression collections,
    \item program-analysis or code-generation tools that synthesize and evaluate patterns automatically,
    \item workloads where pattern matching constitutes a significant fraction of steady-state execution time.
\end{itemize}


\subsection{Contributions}

This paper makes the following contributions:

\begin{enumerate}
    \item A minimal instruction set ($\sim$20 opcodes) tailored to pattern-matching primitives in the Wolfram Language.

    \item A register-based execution model with explicit data flow that eliminates stack-management overhead.
    
    \item A structured backtracking protocol that enables independent exploration of alternatives.
    
    \item An evaluation demonstrating full semantic equivalence with Wolfram Language's \texttt{MatchQ} for all supported pattern constructs.
    
    \item (\emph{In progress}) A suite of optimization passes over compiled patterns, including control-flow simplification and elimination of redundant tests.
    
    \item (\emph{In progress}) Integrated debugging and tracing facilities for visualizing and instrumenting pattern execution at the bytecode level.
    
    \item A complete Wolfram Language paclet providing a high-level API for compiling, executing, and inspecting compiled patterns.
\end{enumerate}


% ============================================================================
% 2. BACKGROUND
% ============================================================================
\section{Background: Pattern Matching in Wolfram Language}
\label{sec:background}

To motivate our design and establish the semantic foundation for our virtual machine, we review the structure of Wolfram Language expressions and the core pattern matching constructs that operate on them.

\subsection{Wolfram Language Expressions}

In the Wolfram Language, \emph{everything is an expression}. Every expression has the
uniform structural form \texttt{head[arg1, arg2, \ldots, argN]}, where the head determines
the expression's type or role and the arguments supply its data. This uniformity applies to
functions, lists, operators, and even atomic values.

Function calls such as \texttt{f[x, y]} have head \texttt{f} and two arguments \texttt{x}
and \texttt{y}. Lists such as \texttt{\{a, b, c\}} are syntactic sugar for
\texttt{List[a, b, c]}. Even atoms---numbers, strings, and symbols---have heads despite
having no arguments:

\begin{itemize}
    \item The integer \texttt{5} has head \texttt{Integer}.
    \item The string \texttt{"hello"} has head \texttt{String}.
    \item The symbol \texttt{x} has head \texttt{Symbol}.
\end{itemize}

The \texttt{Head} function extracts an expression's head, while \texttt{FullForm} reveals
the internal representation used by the evaluator. Representative examples are shown in
Table~\ref{tab:expr-structure}.

\begin{table}[h]
\centering
\begin{tabular}{l l l l}
\toprule
\textbf{Expression} & \textbf{FullForm} & \textbf{Head} & \textbf{Arguments} \\
\midrule
\texttt{x + y}      & \texttt{Plus[x, y]}        & \texttt{Plus}      & \texttt{x, y} \\
\texttt{\{a, b, c\}}  & \texttt{List[a, b, c]}  & \texttt{List}   & \texttt{a, b, c} \\
\texttt{5}            & \texttt{5}              & \texttt{Integer}& none \\
\texttt{"hi"}         & \texttt{"hi"}           & \texttt{String} & none \\
\bottomrule
\end{tabular}
\caption{Examples of Wolfram Language expressions and their internal structure.}
\label{tab:expr-structure}
\end{table}

Although atoms possess heads, they remain indivisible values: their \texttt{FullForm} does
not expand into constructs such as \texttt{Integer[5]} or \texttt{String["hi"]}. The head
encodes semantic type information without altering the underlying representation.

Because every expression---atomic or compound---ultimately forms a tree, it is useful to
make that structure explicit. Figure~\ref{fig:syntax-tree} illustrates the
\texttt{FullForm} structure of the expression \texttt{a*2 + b} and its corresponding syntax
tree.

\begin{figure}[h]
\centering
\begin{tikzpicture}[
  level distance=12mm,
  every node/.style={font=\small},
  level 1/.style={sibling distance=28mm},
  level 2/.style={sibling distance=15mm},
  edge from parent/.style={draw, -latex}
]
\node {Plus}
  child { node {Times}
    child { node {a} }
    child { node {2} }
  }
  child { node {b} };
\end{tikzpicture}
\caption{Syntax tree (FullForm) of the expression \texttt{a*2 + b}, represented internally
as \texttt{Plus[Times[a, 2], b]}.}
\label{fig:syntax-tree}
\end{figure}

This uniform expression model is fundamental to pattern matching. This structural regularity enables a compact instruction set—as we show in Section~3, only 21 opcodes suffice for the entire virtual machine. Patterns specify constraints on heads, argument shapes, and subexpressions, and \texttt{MatchQ} determines
whether a tree satisfies those constraints. Because the representation is homogeneous, these
constraints apply uniformly across all expression types.


\subsection{Core Pattern Constructs}

Pattern constructs specify structural and semantic constraints that an expression must
satisfy in order to match. The Wolfram Language provides a small set of primitive forms
that compose to express rich matching behaviors. Table~\ref{tab:pattern-core} summarizes
the constructs relevant to this work.

\begin{table}[h]
\centering
\small
\begin{tabular}{p{0.28\linewidth} p{0.62\linewidth}}
\toprule
\textbf{Construct} & \textbf{Meaning} \\
\midrule
\texttt{expr} &
Literal structural match \\
\texttt{\_} &
Match any expression \\
\texttt{\_h} &
Match expressions whose head is \texttt{h} \\
\texttt{x\_} &
Named pattern that binds the matched expression to \texttt{x} \\
\texttt{x\_ \dots x\_} &
Repeated named pattern enforcing structural equality across occurrences \\
\texttt{p\,|\,q} &
Alternative: match either pattern \\
\texttt{p?test} &
Pattern test: predicate must evaluate to \texttt{True} \\
\texttt{\_,\ \_\_,\ \_\_\_} &
Sequence patterns (variable-length argument sequences; not supported in this VM) \\
\bottomrule
\end{tabular}
\caption{Core pattern constructs considered in this work.}
\label{tab:pattern-core}
\end{table}

\begin{comment}
A note on notation: a bare symbol such as \texttt{x} is \emph{not} a placeholder---it is
a literal expression that matches only itself. Placeholders require explicit blank
notation (\texttt{\_}, \texttt{x\_}). Additionally, pattern matching operates on the raw
syntactic structure of expressions (``\texttt{HoldComplete} semantics''), so the VM must
expose expressions without evaluation unless a construct explicitly invokes it (e.g.\ a
predicate in \texttt{?}).
\end{comment}

\paragraph{Structural equality.}
Literal patterns match expressions by exact structural identity:
\begin{mmaCell}{Input}
MatchQ[5, 5]
\end{mmaCell}
\begin{mmaCell}{Output}
True
\end{mmaCell}

In contrast, a bare symbol does not act as a pattern:
\begin{mmaCell}{Input}
MatchQ[5, x]
\end{mmaCell}
\begin{mmaCell}{Output}
False
\end{mmaCell}

\paragraph{Blanks.}
A blank (\texttt{\_}) matches any single expression; a typed blank (\texttt{\_h}) matches
only those expressions whose head is \texttt{h}:
\begin{mmaCell}{Input}
\{MatchQ[42, _], MatchQ["hello", _]\}
\end{mmaCell}
\begin{mmaCell}{Output}
\{True, True\}
\end{mmaCell}

\begin{mmaCell}{Input}
MatchQ[f[3], _List]
\end{mmaCell}
\begin{mmaCell}{Output}
False
\end{mmaCell}

\paragraph{Named patterns and variable binding.}
A named pattern \texttt{x\_} binds the matched expression:

\begin{mmaCell}{Input}
Replace[3, x_ :> x^2]
\end{mmaCell}
\begin{mmaCell}{Output}
9
\end{mmaCell}

Repeated occurrences of the same named pattern enforce a structural consistency constraint:
\begin{mmaCell}{Input}
MatchQ[f[5, 5], f[x_, x_]]
\end{mmaCell}
\begin{mmaCell}{Output}
True
\end{mmaCell}

\begin{mmaCell}{Input}
MatchQ[f[5, 42], f[x_, x_]]
\end{mmaCell}
\begin{mmaCell}{Output}
False
\end{mmaCell}

\paragraph{Alternatives.}
The infix construct \texttt{|} expresses choice among patterns:
\begin{mmaCell}{Input}
MatchQ[5, _Integer | _Real]
\end{mmaCell}
\begin{mmaCell}{Output}
True
\end{mmaCell}

A non-matching case illustrates the boundary:
\begin{mmaCell}{Input}
MatchQ["hi", _Integer | _Real]
\end{mmaCell}
\begin{mmaCell}{Output}
False
\end{mmaCell}

\paragraph{Pattern tests.}
The operator \texttt{?} attaches a predicate that must evaluate to \texttt{True} on the
candidate. Predicates are evaluated dynamically in the current environment:

\begin{mmaCell}{Input}
MatchQ[4, _Integer?EvenQ]
\end{mmaCell}
\begin{mmaCell}{Output}
True
\end{mmaCell}

\begin{mmaCell}{Input}
MatchQ[5, _Integer?EvenQ]
\end{mmaCell}
\begin{mmaCell}{Output}
False
\end{mmaCell}

\paragraph{Sequence patterns.}
The constructs \texttt{\_\,\_, \_\_, \_\_\_} match variable-length sequences of arguments.
These are part of the full Wolfram Language but not supported by the virtual machine
presented in this work:
\begin{mmaCell}{Input}
MatchQ[\{1,2,3\}, \{__\}]
\end{mmaCell}
\begin{mmaCell}{Output}
True
\end{mmaCell}

\medskip
Together these constructs form the semantic surface that our virtual machine must
preserve. Although each rule appears small and orthogonal, their interaction---especially
alternatives, repeated variables, and dynamically evaluated pattern tests---generates rich
backtracking behavior. The VM described in this paper compiles these constructs into an
explicit, analyzable instruction set with structured control flow.


\subsection{Pattern Matching Functions}

Wolfram Language provides several built-in functions that rely on pattern matching. Our virtual machine models the core matching semantics required by these functions.

\paragraph{MatchQ.} Tests whether an expression matches a pattern:
\begin{mmaCell}{Input}
MatchQ[\{1, 2, 3\}, {_, _, _}]
\end{mmaCell}
\begin{mmaCell}{Output}
True
\end{mmaCell}

\paragraph{Replace.} Applies transformation rules by matching patterns and substituting bound values:
\begin{mmaCell}{Input}
Replace[\{1, 2, 3\}, {x_, y_, z_} :> {z, y, x}]
\end{mmaCell}
\begin{mmaCell}{Output}
\{3, 2, 1\}
\end{mmaCell}

\paragraph{Cases.} Filters expressions by pattern:
\begin{mmaCell}{Input}
Cases[\{1, "x", 2, "y"\}, _Integer]
\end{mmaCell}
\begin{mmaCell}{Output}
\{1, 2\}
\end{mmaCell}

\paragraph{ReplaceAll (/.)} Applies rules recursively throughout an expression:
\begin{mmaCell}{Input}
\{f[1], f[2]\} /. f[x_] :> g[x]
\end{mmaCell}
\begin{mmaCell}{Output}
\{g[1], g[2]\}
\end{mmaCell}


\subsection{Pattern-Based Function Definitions}

One of the most powerful applications of pattern matching is defining functions that dispatch on the structure of their arguments. Unlike traditional function definitions that match only by argument count, pattern-based definitions can inspect argument types, values, and structure.

\textbf{Basic pattern dispatch:} Functions can have multiple definitions with different patterns. The system selects the first definition whose pattern matches the input:
\begin{mmaCell}{Input}
fac[0] := 1
fac[n_] := n * fac[n - 1]
fac[5]
\end{mmaCell}
\begin{mmaCell}{Output}
120
\end{mmaCell}

When \texttt{fac[5]} is called, the first definition (\texttt{fac[0]}) fails because \texttt{5 != 0}, so the second definition matches with \texttt{n} bound to \texttt{5}.

\textbf{Type-based dispatch:} Patterns can discriminate expressions by their head, enabling different behavior for different data "types":
\begin{mmaCell}{Input}
process[_Integer] := "number"
process[_String] := "text"
process[_List] := "list"
\end{mmaCell}

\begin{mmaCell}{Input}
\{process[42], process["hello"], process[\{1,2\}]\}
\end{mmaCell}
\begin{mmaCell}{Output}
\{"number", "text", "list"\}
\end{mmaCell}

\textbf{Structural constraints:} Patterns can match specific structures, enabling dispatch based on shape:
\begin{mmaCell}{Input}
distance[\{x_, y_\}] := Sqrt[x^2 + y^2]
distance[\{x_, y_, z_\}] := Sqrt[x^2 + y^2 + z^2]
\end{mmaCell}

\begin{mmaCell}{Input}
\{distance[\{3, 4\}], distance[\{1, 2, 2\}]\}
\end{mmaCell}
\begin{mmaCell}{Output}
\{5, 3\}
\end{mmaCell}

Pattern-based definitions are evaluated repeatedly whenever the function is called. For frequently invoked functions, the overhead of interpreting pattern structures on every call becomes significant, motivating the need for pattern compilation.

\subsection{Why Compilation Matters}

The current interpretive implementation of pattern matching has several limitations:

\textbf{Repeated evaluation cost}: Each pattern match traverses the pattern structure recursively, even for patterns used repeatedly. In a function called thousands of times, this overhead accumulates.

\textbf{Opaque control flow}: The backtracking behavior when alternatives fail is implicit in the recursive evaluation, making it difficult to trace, debug, or optimize.

\textbf{Limited observability}: Users cannot inspect how a pattern is being evaluated, what alternatives were tried, or where time is spent.

\textbf{No optimization opportunity}: Because patterns are evaluated directly, there is no opportunity to apply optimizations like redundant test elimination or constant folding.

Our virtual machine addresses these issues by:
\begin{itemize}
    \item Compiling patterns once to bytecode that can be executed many times
    \item Making backtracking explicit through the TRY/RETRY/TRUST protocol
    \item Exposing execution metrics (instruction count, cycles, backtrack events)
    \item Creating an intermediate representation amenable to optimization passes
\end{itemize}

Having established the semantic foundation of Wolfram Language pattern matching, we now describe how these operations can be compiled to efficient bytecode.

% ============================================================================
% 3. DESIGN
% ============================================================================
\section{Design}

\subsection{Design Principles}

The virtual machine design follows these principles:

\begin{enumerate}
    \item \textbf{Minimality}: Use the smallest instruction set sufficient for pattern matching, avoiding feature creep and maintaining conceptual clarity. Wolfram Language's uniform \texttt{head[args]} representation enables this: since every expression conforms to the same structural template, only a small instruction set is required. The VM requires only 21 opcodes compared to 200+ in the JVM or 100+ in Python bytecode.
    
    \item \textbf{Explicit control flow}: Replace implicit recursive traversal with direct jumps and structured backtracking, making execution observable. Every control transfer uses explicit labels rather than hidden function calls or stack unwinding. No special-case handling is needed for different expression categories—instructions for inspecting heads, navigating argument lists, and testing structural properties work uniformly, and backtracking behavior can be implemented consistently across all pattern constructs.
    
    \item \textbf{Orthogonality}: Each instruction performs one well-defined operation; complexity emerges from composition, not individual instruction semantics. For example, \texttt{MATCH\_HEAD} only tests heads—it does not also bind variables or extract subexpressions.
    
    \item \textbf{Correctness over performance}: Prioritize semantic equivalence with native \texttt{MatchQ} over speed optimizations. The struct-based instruction encoding (Section~\ref{sec:impl-encoding}) trades memory efficiency for implementation clarity.
    
    \item \textbf{Observability}: Expose execution state (registers, bytecode, metrics) for debugging, analysis, and education. Every aspect of VM state can be inspected, traced, or instrumented.
\end{enumerate}

\subsection{Scope}

This work focuses on core pattern matching features that represent the essential building blocks of pattern-based computation. Our goal is to demonstrate that a minimal, well-designed virtual machine can correctly implement these fundamental operations with explicit backtracking control.

\subsubsection{Supported Pattern Constructs}

The system supports seven core pattern constructs (described in Section~\ref{sec:background}):

\begin{itemize}
    \item \textbf{Literal patterns} (\texttt{5}, \texttt{Pi}) - exact structural matching
    \item \textbf{Blank patterns} (\texttt{\_}, \texttt{\_Integer}) - wildcards with optional head constraints
    \item \textbf{Named patterns} (\texttt{x\_}) - variable binding and capture
    \item \textbf{Repeated variables} (\texttt{f[x\_, x\_]}) - equality constraints across positions
    \item \textbf{Alternatives} (\texttt{p1 | p2}) - non-deterministic choice requiring backtracking (see Section~\ref{sec:backtracking})
    \item \textbf{Structured patterns} (\texttt{f[x\_, y\_]}) - compound expression decomposition
    \item \textbf{Pattern tests} (\texttt{\_?EvenQ}) - predicate application
\end{itemize}

These constructs cover the most commonly used pattern matching operations and demonstrate all key aspects of the VM architecture: structural decomposition, variable binding, equality testing, alternatives with backtracking, and dynamic predicate evaluation.

\subsubsection{Design Goals}

Our primary goal is \textbf{demonstrating feasibility and correctness} rather than achieving performance parity with Wolfram Language's highly optimized native \texttt{MatchQ} implementation. We focus on five key questions:

\begin{enumerate}
    \item Can we express pattern matching with $\sim$20 opcodes? (Minimality)
    \item Does the register-based design make control flow explicit? (Clarity)
    \item Do we achieve 100\% semantic equivalence with \texttt{MatchQ}? (Correctness)
    \item Can we expose execution metrics for analysis? (Observability)
    \item Does the design support adding new pattern constructs? (Extensibility)
\end{enumerate}

Section~\ref{sec:evaluation} demonstrates affirmative answers to all five questions. The system conclusively shows that pattern compilation is feasible with a clean, minimal design. While raw execution speed is not our primary concern, compilation provides inherent advantages: amortization across repeated uses, bytecode caching, and a foundation for optimization passes.

Advanced features such as sequence patterns (\texttt{\_\_}, \texttt{\_\_\_}), conditional patterns (\texttt{/;}), optional patterns (\texttt{x\_.}), orderless matching, and pattern modifiers are discussed in Section~\ref{sec:future} as natural extensions of the core architecture.

\subsection{Register Model}

The VM uses a register-based architecture with two distinct register types, chosen for explicit data flow and simplified instruction encoding.

\subsubsection{Register Types}

The VM maintains two separate register files. We use assembly-like notation where \texttt{\%e0} denotes expression register 0, \texttt{\%b0} denotes boolean register 0, and so on:

\begin{center}
\small
\begin{tabular}{@{}lp{3.5cm}@{}}
\toprule
\textbf{Type} & \textbf{Purpose} \\
\midrule
\texttt{\%e0} & Current match target \\
\texttt{\%e1, \%e2, ...} & Subexpressions, temps \\
\midrule
\texttt{\%b0} & Final result (True/False) \\
\texttt{\%b1, \%b2, ...} & Intermediate comparisons \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Expression registers} (\texttt{\%e0}, \texttt{\%e1}, \texttt{\%e2}, ...): 
Hold Wolfram \texttt{Expr} values representing expressions being matched or decomposed. 
By convention, \texttt{\%e0} always contains the current match target—the expression 
being tested against the pattern.

\textbf{Boolean registers} (\texttt{\%b0}, \texttt{\%b1}, \texttt{\%b2}, ...): 
Hold comparison results from \texttt{SAMEQ} and other boolean operations. 
By convention, \texttt{\%b0} contains the final match result returned by the \texttt{HALT} operation.

Separate register types provide \textbf{static type safety}: the instruction set enforces 
that expression operations (e.g., \texttt{GET\_PART}) operate only on expression registers, 
while boolean operations (e.g., \texttt{BRANCH\_FALSE}) operate only on boolean registers. 
This catches type errors at compile time rather than runtime.

\subsubsection{Register Allocation Model}

The compiler uses an \textbf{unlimited register model}: each distinct value is allocated 
a fresh register without reuse or spilling. While this may allocate more registers 
than strictly necessary, it:

\begin{itemize}
    \item \textbf{Simplifies compilation}: No register allocation conflicts or 
    interference analysis required
    
    \item \textbf{Preserves values}: Intermediate results remain available throughout 
    pattern matching, useful for backtracking
    
    \item \textbf{Makes data flow explicit}: Each register has a clear semantic role 
    (e.g., \texttt{\%e1} = first argument, \texttt{\%e2} = second argument)
\end{itemize}

This register-based design contrasts with traditional stack-based VMs (JVM, Python)\cite{fang2016}. 
Advantages include: (1) fewer instructions—no explicit \texttt{PUSH}/\texttt{POP} operations, 
(2) explicit data flow—register names show where values come from and go to, 
and (3) simpler backtracking—choice points save register snapshots directly without managing stack frames. For example, comparing two subexpressions requires 5 stack operations but only 1 register operation (\texttt{SAMEQ \%b1, \%e2, \%e3}).

Future work includes register coalescing optimizations to reduce register pressure.

\subsubsection{Register Conventions}

Register usage follows strict conventions to ensure predictable compilation:

\begin{itemize}
    \item \texttt{\%e0}: Always holds the current expression being matched. Instructions like \texttt{MATCH\_HEAD} implicitly operate on \texttt{\%e0}.
    
    \item \texttt{\%b0}: Always holds the final match result. The \texttt{HALT} instruction returns this value.
    
    \item \texttt{\%e1, \%e2, ...}: Allocated sequentially for subexpressions, arguments, and captured variables.
    
    \item \texttt{\%b1, \%b2, ...}: Allocated for intermediate comparison results in patterns with multiple equality constraints.
\end{itemize}

\textbf{Example:} Matching \texttt{f[x\_, x\_]} against \texttt{f[5, 5]} uses registers as follows (reading top to bottom shows the data flow during execution):

\begin{lstlisting}[style=bytecode,numbers=none]
%e0 = f[5, 5]          ; Input expression
%e1 = f[5, 5]          ; Saved copy
%e2 = 5                ; First argument (x)
%e3 = 5                ; Second argument
%b1 = (%e2 == %e3)     ; Equality check
%b0 = True             ; Final result
\end{lstlisting}

The register assignments make data flow transparent: \texttt{\%e2} holds the first 
binding of \texttt{x}, and \texttt{\%e3} is compared against it. This pattern uses 
4 expression registers and 2 boolean registers—typical for a simple equality constraint.

\subsection{Instruction Set Architecture}
\label{sec:isa}

The instruction set consists of 21 opcodes organized into six functional categories: Data Movement, Pattern Matching, Comparison and Binding, Control Flow, Scope Management, and Backtracking. The design prioritizes \textbf{minimality} (fewest instructions needed for completeness), \textbf{orthogonality} (each instruction has one well-defined purpose), and \textbf{efficiency} (fused operations reduce instruction count).

\subsubsection{Design Rationale}

Three key design decisions shape the instruction set:

\textbf{Fused test-and-branch operations:} Instructions like \texttt{MATCH\_HEAD} combine testing with conditional control flow, eliminating intermediate boolean values and reducing instruction count. Empirically, this reduces average bytecode size by 15-20\% compared to unfused designs.

\textbf{Specialized pattern primitives:} Rather than general-purpose operations, instructions directly express pattern matching semantics (\texttt{MATCH\_HEAD}, \texttt{GET\_PART}, \texttt{BIND\_VAR}). This makes compilation straightforward and bytecode self-documenting.

\textbf{Explicit backtracking protocol:} The \texttt{TRY}/\texttt{RETRY}/\texttt{TRUST} sequence (adapted from the Warren Abstract Machine\cite{ait-kaci1999}) provides structured control over non-deterministic choice, making backtracking observable and analyzable.

\subsubsection{Instruction Categories}

Many instructions fuse testing with conditional branching to reduce instruction count. For example, checking if an expression has head \texttt{Integer}:

\textbf{Unfused approach} (3 instructions):
\begin{lstlisting}[style=bytecode,numbers=none]
GET_HEAD %e1, %e0
SAMEQ %b1, %e1, Integer
BRANCH_FALSE %b1, Lfail
\end{lstlisting}

\textbf{Fused approach} (1 instruction):
\begin{lstlisting}[style=bytecode,numbers=none]
MATCH_HEAD %e0, Integer, Lfail
\end{lstlisting}

This eliminates two instructions and avoids temporary register allocation. The complete instruction set is organized into six categories (register notation: \texttt{E}=expression, \texttt{B}=boolean, \texttt{L}=label, \texttt{v}=value, \texttt{i}=integer):

\medskip
\noindent\textbf{Data Movement}
\vspace{-0.3em}
\begin{center}
\small
\begin{tabular}{@{}ll@{}}
\texttt{MOVE E$_1$ E$_2$} & \texttt{E$_1$ := E$_2$} \\
\texttt{LOAD\_IMM E v} & \texttt{E := v} \\
\texttt{GET\_PART E$_1$ E$_2$ i} & \texttt{E$_1$ := E$_2$[[i]]} \\
\end{tabular}
\end{center}

\medskip
\noindent\textbf{Pattern Matching (Fused Operations)}
\vspace{-0.3em}
\begin{center}
\small
\begin{tabular}{@{}ll@{}}
\texttt{MATCH\_HEAD E h L} & if \texttt{Head[E] $\neq$ h} goto \texttt{L} \\
\texttt{MATCH\_LENGTH E n L} & if \texttt{Length[E] $\neq$ n} goto \texttt{L} \\
\texttt{MATCH\_LITERAL E v L} & if \texttt{E $\neq$ v} goto \texttt{L} \\
\texttt{APPLY\_TEST E f L} & if \texttt{f[E] $\neq$ True} goto \texttt{L} \\
\end{tabular}
\end{center}

\medskip
\noindent\textbf{Comparison and Binding}
\vspace{-0.3em}
\begin{center}
\small
\begin{tabular}{@{}ll@{}}
\texttt{SAMEQ B E$_1$ E$_2$} & \texttt{B := SameQ[E$_1$, E$_2$]} \\
\texttt{BIND\_VAR name E} & bind \texttt{name := E} \\
\end{tabular}
\end{center}

\medskip
\noindent\textbf{Control Flow}
\vspace{-0.3em}
\begin{center}
\small
\begin{tabular}{@{}ll@{}}
\texttt{JUMP L} & goto \texttt{L} \\
\texttt{BRANCH\_FALSE B L} & if \texttt{B = False} goto \texttt{L} \\
\texttt{HALT} & return \texttt{\%b0} \\
\end{tabular}
\end{center}

\medskip
\noindent\textbf{Scope Management}
\vspace{-0.3em}
\begin{center}
\small
\begin{tabular}{@{}ll@{}}
\texttt{BEGIN\_BLOCK} & push binding frame \\
\texttt{END\_BLOCK} & pop and merge frame \\
\texttt{EXPORT\_BINDINGS} & copy bindings to result \\
\end{tabular}
\end{center}

\medskip
\noindent\textbf{Backtracking}
\vspace{-0.3em}
\begin{center}
\small
\begin{tabular}{@{}ll@{}}
\texttt{TRY L} & push choice point for \texttt{L} \\
\texttt{RETRY L} & update choice point to \texttt{L} \\
\texttt{TRUST} & pop choice point \\
\texttt{FAIL} & backtrack to choice point \\
\end{tabular}
\end{center}

\medskip
\noindent Backtracking instructions implement the Warren Abstract Machine protocol (Section~\ref{sec:backtracking}).

\subsubsection{Example: Compiling Simple Patterns}

To illustrate how instructions compose, we show bytecode for three patterns of increasing complexity.

\textbf{Example 1: Type constraint (\texttt{\_Integer})}

\begin{lstlisting}[style=bytecode]
L0:
  MATCH_HEAD %e0, Integer, L_fail  ; Fused test-and-branch
  LOAD_IMM %b0, true
  HALT

L_fail:
  LOAD_IMM %b0, false
  HALT
\end{lstlisting}

The single \texttt{MATCH\_HEAD} instruction (Pattern Matching category) performs the entire test, demonstrating the benefit of fused operations discussed above.

\textbf{Example 2: Structured pattern (\texttt{f[\_Integer]})}

\begin{lstlisting}[style=bytecode]
L0:
  MATCH_LENGTH %e0, 1, L_fail     ; Must have 1 argument
  MATCH_HEAD %e0, f, L_fail       ; Head must be f
  
  GET_PART %e1, %e0, 1            ; Extract first argument
  MATCH_HEAD %e1, Integer, L_fail ; Check argument is Integer
  
  LOAD_IMM %b0, true
  HALT

L_fail:
  LOAD_IMM %b0, false
  HALT
\end{lstlisting}

This combines structural decomposition (\texttt{MATCH\_LENGTH}, \texttt{GET\_PART} from Data Movement) with type testing (\texttt{MATCH\_HEAD}). The pattern requires 4 fused operations plus argument extraction.

\textbf{Example 3: Repeated variable (\texttt{f[x\_, x\_]})}

\begin{lstlisting}[style=bytecode]
L0:
  MATCH_LENGTH %e0, 2, L_fail
  MATCH_HEAD %e0, f, L_fail
  
  GET_PART %e1, %e0, 1           ; Extract first argument
  BIND_VAR "Global`x", %e1       ; Bind to x (first occurrence)
  
  GET_PART %e2, %e0, 2           ; Extract second argument
  SAMEQ %b1, %e1, %e2            ; Check x == x (repeated variable)
  BRANCH_FALSE %b1, L_fail       ; Fail if not equal
  
  LOAD_IMM %b0, true
  HALT

L_fail:
  LOAD_IMM %b0, false
  HALT
\end{lstlisting}

This demonstrates variable binding (\texttt{BIND\_VAR} from Comparison and Binding category) on first occurrence and equality checking (\texttt{SAMEQ}) for subsequent occurrences. The compiler tracks variable occurrences in its lexical environment, emitting different instruction sequences for first vs. repeated uses (see Section~\ref{sec:compilation}).

\subsubsection{Instruction Encoding}

Instructions consist of an opcode identifier and a variable-length list of operands. Operands are tagged to distinguish between register types (expression vs. boolean), labels for control flow, variable names for binding, and immediate values (constants). This typed operand model ensures that, for example, a boolean register cannot be accidentally used where an expression register is required.

The encoding is designed to support the operand types introduced in the instruction categories: \texttt{E} (expression registers), \texttt{B} (boolean registers), \texttt{L} (labels), variable names, and immediate values (\texttt{v}, \texttt{i}). The current implementation uses a struct-based representation for simplicity and debuggability; future work will explore byte-oriented formats for improved memory density, following established patterns from production VMs. Implementation details are discussed in Section~\ref{sec:impl-encoding}.

Table~\ref{tab:isa} provides a complete reference of all opcodes, organized by category.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}llp{5cm}@{}}
\toprule
\textbf{Opcode} & \textbf{Category} & \textbf{Description} \\
\midrule
\texttt{MOVE} & Data & Copy between registers \\
\texttt{LOAD\_IMM} & Data & Load constant \\
\texttt{GET\_PART} & Data & Extract expression part \\
\midrule
\texttt{MATCH\_HEAD} & Match & Test head, jump on fail \\
\texttt{MATCH\_LENGTH} & Match & Test length, jump on fail \\
\texttt{MATCH\_LITERAL} & Match & Test equality, jump on fail \\
\texttt{APPLY\_TEST} & Match & Apply predicate, jump on fail \\
\midrule
\texttt{SAMEQ} & Compare & Structural equality test \\
\texttt{BIND\_VAR} & Binding & Bind variable \\
\midrule
\texttt{JUMP} & Control & Unconditional jump \\
\texttt{BRANCH\_FALSE} & Control & Conditional jump \\
\texttt{HALT} & Control & Stop execution \\
\midrule
\texttt{BEGIN\_BLOCK} & Scope & Create frame \\
\texttt{END\_BLOCK} & Scope & Merge frame \\
\texttt{EXPORT\_BINDINGS} & Scope & Export to result \\
\midrule
\texttt{TRY} & Backtrack & Create choice point \\
\texttt{RETRY} & Backtrack & Update choice point \\
\texttt{TRUST} & Backtrack & Remove choice point \\
\texttt{FAIL} & Backtrack & Backtrack \\
\midrule
\texttt{DEBUG\_PRINT} & Debug & Trace execution \\
\bottomrule
\end{tabular}
\caption{Complete instruction set reference}
\label{tab:isa}
\end{table}

Four of the 20 instructions (\texttt{TRY}, \texttt{RETRY}, \texttt{TRUST}, \texttt{FAIL}) implement the backtracking protocol. This protocol is the VM's most sophisticated mechanism, enabling non-deterministic pattern matching through structured state management.

\subsection{Backtracking Mechanism}
\label{sec:backtracking}

Alternatives in pattern matching (\texttt{p1 | p2 | p3}) require non-deterministic exploration: when one alternative fails, the system must "undo" its effects and try the next. This section describes how the VM implements backtracking, adapting the Warren Abstract Machine (WAM)\cite{ait-kaci1999} protocol to pattern matching.

\subsubsection{Motivating Example}

Consider matching the pattern \texttt{x\_Integer | x\_Real} against the input \texttt{3.14}. The execution proceeds:

\begin{enumerate}
    \item Try first alternative (\texttt{x\_Integer}):
    \begin{itemize}
        \item Check head: Is \texttt{3.14} an \texttt{Integer}? → \textbf{No, fails}
        \item Need to try second alternative
    \end{itemize}
    
    \item Before trying second alternative, restore state:
    \begin{itemize}
        \item Any variable bindings from first attempt must be cleared
        \item Any temporary values in registers must be reset
    \end{itemize}
    
    \item Try second alternative (\texttt{x\_Real}):
    \begin{itemize}
        \item Check head: Is \texttt{3.14} a \texttt{Real}? → \textbf{Yes, succeeds}
        \item Bind \texttt{x} to \texttt{3.14}
        \item Return \texttt{True}
    \end{itemize}
\end{enumerate}

The key challenge: when the first alternative fails, how does the VM know what state to restore? The answer: \textbf{save a snapshot before trying each alternative}.

\subsubsection{The TRY/RETRY/TRUST Protocol}

The VM uses three instructions to manage these snapshots, called \textbf{choice points}:

\begin{itemize}
    \item \texttt{TRY L}: "Save current state. If this alternative fails, try the code at label L instead."
    \item \texttt{RETRY L'}: "Update the saved state to point to label L' as the next fallback."
    \item \texttt{TRUST}: "This is the last alternative—no more fallback positions. Remove the saved state."
\end{itemize}

For \texttt{\_Integer | \_Real | \_String}, the compiled bytecode looks like:

\begin{lstlisting}[style=bytecode,numbers=none]
  TRY L_alt2              ; Save state, fallback = L_alt2
L_alt1:
  MATCH_HEAD %e0, Integer, L_alt1_fail
  JUMP L_success
L_alt1_fail:
  FAIL                    ; Restore state, jump to L_alt2

L_alt2:
  RETRY L_alt3            ; Update fallback = L_alt3
  MATCH_HEAD %e0, Real, L_alt2_fail
  JUMP L_success
L_alt2_fail:
  FAIL                    ; Restore state, jump to L_alt3

L_alt3:
  TRUST                   ; Last alternative, remove saved state
  MATCH_HEAD %e0, String, L_fail
  JUMP L_success
\end{lstlisting}

When \texttt{FAIL} executes, it restores the saved state and jumps to the recorded fallback label. The choice point remains on the stack—\texttt{RETRY} updates it, \texttt{TRUST} removes it.

\subsubsection{What Gets Saved in a Choice Point}

Each choice point is a snapshot containing:
\begin{itemize}
    \item \textbf{Fallback label}: Where to jump on \texttt{FAIL}
    \item \textbf{Registers}: Copies of all expression (\texttt{\%e0}, \texttt{\%e1}, ...) and boolean (\texttt{\%b0}, \texttt{\%b1}, ...) registers
    \item \textbf{Trail mark}: Position in the trail (explained below)
    \item \textbf{Frame depth}: How many scope frames were active
\end{itemize}

Choice points are pushed onto a stack. When \texttt{FAIL} triggers, the VM pops the topmost choice point and restores its saved values.

\subsubsection{The Trail: Undoing Variable Bindings}

Consider the pattern \texttt{f[x\_] | g[x\_]} matching against \texttt{f[5]}. During the first alternative:
\begin{enumerate}
    \item Match succeeds, variable \texttt{x} is bound to \texttt{5}
    \item Suppose a later test fails, triggering \texttt{FAIL}
    \item Before trying the second alternative, \texttt{x} must be unbound
\end{enumerate}

The \textbf{trail} records every variable binding made during pattern matching. Each entry stores:
\begin{itemize}
    \item Variable name (e.g., \texttt{"Global`x"})
    \item Frame index (which scope the binding belongs to)
\end{itemize}

When backtracking, the VM unwinds the trail in reverse order (LIFO), erasing bindings back to the position saved in the choice point. This ensures each alternative starts with a clean variable environment.

\textbf{Optimization}: The trail is only used when choice points exist. In deterministic patterns (no alternatives), \texttt{BIND\_VAR} skips trailing entirely, eliminating 15-25\% overhead. The instruction checks if the choice point stack is empty before deciding whether to record bindings.

\subsubsection{Frames: Lexical Scoping}

Frames manage variable bindings in nested scopes. Each \texttt{BEGIN\_BLOCK} creates a frame, and \texttt{END\_BLOCK} removes it. When backtracking restores "frame depth," it ensures the scope stack returns to the state it had when the choice point was created. This prevents bindings from leaking between alternatives or pattern substructure.

\subsubsection{Execution Example}

Matching \texttt{\_Integer | \_Real | \_String} against input \texttt{3.14} (head = \texttt{Real}):

\begin{enumerate}
    \item Execute \texttt{TRY L\_alt2}: Save state (registers, trail position, frame depth), record fallback = L\_alt2
    \item Try first alternative: \texttt{MATCH\_HEAD \%e0, Integer, L\_alt1\_fail}
    \item Head is \texttt{Real} ≠ \texttt{Integer} → Jump to L\_alt1\_fail
    \item Execute \texttt{FAIL}: Restore saved state, jump to L\_alt2
    \item Execute \texttt{RETRY L\_alt3}: Update fallback to L\_alt3
    \item Try second alternative: \texttt{MATCH\_HEAD \%e0, Real, L\_alt2\_fail}
    \item Head is \texttt{Real} = \texttt{Real} → \textbf{Success!}
    \item Jump to L\_success, match returns \texttt{True}
\end{enumerate}

The choice point created by \texttt{TRY} enabled recovery from the first failure. See Section~\ref{sec:compilation} for how the compiler generates this bytecode from alternatives.

% ============================================================================
% 4. COMPILATION
% ============================================================================
\section{Compilation Strategy}
\label{sec:compilation}

The compiler transforms Wolfram Language patterns into the bytecode instruction set described in Section~\ref{sec:isa}. Compilation proceeds in a single pass through recursive descent over the pattern's Abstract Syntax Tree (AST), generating instruction sequences that preserve the pattern's matching semantics while making control flow and backtracking explicit.

This section first outlines the compiler's design philosophy and architecture (Section~4.1), then illustrates bytecode generation for each pattern construct through concrete examples (Section~4.2), progressing from simple literals to complex alternatives with backtracking.

\subsection{Design Rationale and Architecture}

Four key principles guide the compiler design:

\textbf{Single-pass compilation} avoids the complexity of building intermediate representations like decision trees or control-flow graphs, prioritizing implementation clarity over sophisticated optimization. The compiler generates bytecode directly during a single recursive descent through the pattern AST.

\textbf{Lexical environment at compile-time} tracks variable names and their allocated registers during compilation. This enables detecting repeated variables (e.g., \texttt{f[x\_, x\_]}) statically, generating efficient equality checks rather than runtime symbol table lookups.

\textbf{Fused match operations} combine testing and branching in single instructions (e.g., \texttt{MATCH\_HEAD}), reducing bytecode size by 15-20\% compared to unfused designs and improving cache locality during execution.

\textbf{Unlimited register allocation} simplifies the compiler by avoiding register allocation conflicts and interference analysis. Each distinct value receives a fresh register, at the cost of potentially allocating more registers than strictly necessary. This trade-off prioritizes compilation simplicity and maintains explicit data flow in the generated bytecode.

\subsubsection{Compiler Structure}

The compiler interface is a recursive function with the following signature:

\begin{lstlisting}[style=wolfram,numbers=none]
compile(state, pattern, Lsuccess, Lfail, isTop)
\end{lstlisting}

Parameters specify the pattern to compile, success and failure target labels for control flow, and whether the pattern appears at the top level (requiring an explicit success jump). The function returns generated bytecode and an updated compiler state.

The compiler maintains four components of state:
\begin{itemize}
    \item \textbf{Register allocation counters}: Track next available expression and boolean register indices
    \item \textbf{Label generation counter}: Ensures unique labels for control flow targets
    \item \textbf{Lexical environment}: Maps variable names to allocated registers
    \item \textbf{Bytecode accumulator}: Collects generated instructions
\end{itemize}

These data structures enable single-pass compilation while preserving variable binding information and maintaining unique identifiers for control flow.

Having established the compiler's architecture and design principles, we now turn to concrete examples of bytecode generation.

\subsection{Bytecode Generation by Pattern Construct}

We now illustrate bytecode generation for each supported pattern construct, progressing from simple literals through complex alternatives. Each example shows the source pattern, the generated bytecode, and explains key compilation decisions that connect to the design principles above.

\subsubsection{Literal Patterns}

Literal values such as \texttt{5} or \texttt{Pi} require exact structural equality:
\begin{lstlisting}[style=bytecode,numbers=none]
MATCH_LITERAL %e0, 5, Lfail
JUMP Lsuccess
\end{lstlisting}

The \texttt{MATCH\_LITERAL} instruction embodies the fused operation principle: it combines structural equality testing (\texttt{SameQ}) with conditional branching in a single opcode. If the test fails, execution jumps directly to \texttt{Lfail}; otherwise, control falls through to the success path. This eliminates two instructions (separate test and branch) and avoids allocating a temporary boolean register.

\subsubsection{Blank Patterns}

An unconstrained blank (\texttt{\_}) matches any expression and generates only a success jump—no runtime test is needed. A typed blank (\texttt{\_Integer}) adds a head constraint:

\begin{lstlisting}[style=bytecode,numbers=none]
MATCH_HEAD %e0, Integer, Lfail
JUMP Lsuccess
\end{lstlisting}

Again, the fused \texttt{MATCH\_HEAD} instruction tests the head and branches in one operation. The bytecode for typed blanks is identical in structure to literals, differing only in the test performed (head equality vs. structural equality).

\subsubsection{Named Patterns: First Occurrence and Binding}

Pattern \texttt{x\_Integer} compiles to:
\begin{lstlisting}[style=bytecode,numbers=none]
MATCH_HEAD %e0, Integer, Linner
MOVE %e1, %e0
BIND_VAR "x", %e1
JUMP Lsuccess
Linner:
JUMP Lfail
\end{lstlisting}

The compiler allocates a fresh register (\texttt{\%e1}) for the matched value, records the mapping \texttt{x → \%e1} in its lexical environment, and emits a \texttt{BIND\_VAR} instruction. This compile-time tracking enables efficient handling of repeated variables (next subsection).

\subsubsection{Named Patterns: Repeated Occurrences and Equality}

When a variable appears multiple times (e.g., the second \texttt{x} in \texttt{f[x\_, x\_]}), the compiler looks up its register from the lexical environment and generates an equality test instead of a binding:

\begin{lstlisting}[style=bytecode,numbers=none]
; (after compiling first x_ and binding to %e1)
SAMEQ %b1, %e1, %e0  ; %e1 = previously bound x
BRANCH_FALSE %b1, Lfail
\end{lstlisting}

No \texttt{BIND\_VAR} is emitted. The compile-time lexical environment enables distinguishing first occurrences (which bind) from subsequent occurrences (which test), generating different bytecode for each case without runtime overhead.

\subsubsection{Structured Patterns}

Compound patterns like \texttt{f[x\_, y\_]} require decomposing the expression and recursively compiling subpatterns:
\begin{lstlisting}[style=bytecode,numbers=none]
MATCH_LENGTH %e0, 2, Lfail
MATCH_HEAD %e0, f, Lfail
MOVE %e1, %e0           ; Save f[x,y]

GET_PART %e2, %e0, 1    ; First arg
MOVE %e0, %e2
; ... compile x_ ...
MOVE %e0, %e1           ; Restore

GET_PART %e3, %e0, 2    ; Second arg  
MOVE %e0, %e3
; ... compile y_ ...

JUMP Lsuccess
\end{lstlisting}

The compiler first validates structural properties (argument count and head), then extracts each argument into a fresh register via \texttt{GET\_PART}. The convention that \texttt{\%e0} holds the current match target requires saving and restoring the parent expression around each recursive subpattern compilation. This protocol—maintaining \texttt{\%e0} as the match target throughout—simplifies the recursive compilation logic at the cost of extra \texttt{MOVE} instructions.

\subsubsection{Alternatives and Backtracking}

Alternatives (\texttt{p1 | p2 | p3}) represent the most complex compilation case, requiring the TRY/RETRY/TRUST protocol described in Section~\ref{sec:backtracking}:
\begin{lstlisting}[style=bytecode,numbers=none]
TRY Lp2
Lp1:
; ... compile p1 ...
JUMP Llocal_success
; ... p1 failure handler ...
FAIL

Lp2:
RETRY Lp3
; ... compile p2 ...
JUMP Llocal_success
; ... p2 failure handler ...
FAIL

Lp3:
TRUST
; ... compile p3 ...
JUMP Llocal_success

Llocal_success:
JUMP Lsuccess
\end{lstlisting}

The first alternative begins with \texttt{TRY}, creating a choice point that saves VM state and records the fallback label (\texttt{Lp2}). Middle alternatives use \texttt{RETRY} to update the fallback, while the final alternative uses \texttt{TRUST} to remove the choice point (no further alternatives exist). When any alternative succeeds, it jumps to \texttt{Llocal\_success}; when one fails, \texttt{FAIL} backtracks to the saved choice point.

Critically, each alternative is compiled with a fresh lexical environment. The compiler does not propagate variable bindings from one alternative to another, ensuring that failed alternatives do not pollute the variable namespace.

\subsubsection{Pattern Tests}

Pattern tests (\texttt{?}) apply user-defined predicates to matched values:
\begin{lstlisting}[style=bytecode,numbers=none]
MATCH_HEAD %e0, Integer, Lfail
APPLY_TEST %e0, EvenQ, Lfail
JUMP Lsuccess
\end{lstlisting}

The compiler first emits instructions for the base pattern (\texttt{\_Integer}), then appends the test. The \texttt{APPLY\_TEST} instruction evaluates the predicate function in the Wolfram Language runtime environment, enabling arbitrary user-defined tests that require dynamic evaluation. This provides an escape hatch from the bytecode world back to interpreted evaluation when predicates involve computation beyond simple structural tests, preserving the full expressiveness of Wolfram Language pattern matching while keeping the common path (structural matching) in compiled bytecode.

% ============================================================================
% 5. EVALUATION
% ============================================================================
\section{Evaluation}
\label{sec:evaluation}

\subsection{Correctness Validation}

We verify semantic equivalence with native \texttt{MatchQ} through systematic testing:

\begin{lstlisting}[style=wolfram,numbers=none]
testEquivalence[pat_, expr_] := 
  PatternMatcherExecute[pat, expr]["Result"] 
  === MatchQ[expr, pat]
\end{lstlisting}

\textbf{Test coverage:} 54 test cases across all supported pattern constructs achieve 100\% equivalence with native \texttt{MatchQ}.

\begin{table}[h]
\centering
\small
\begin{tabular}{lcc}
\toprule
\textbf{Pattern Type} & \textbf{Tests} & \textbf{Pass Rate} \\
\midrule
Literals & 8 & 100\% \\
Blanks & 6 & 100\% \\
Named patterns & 10 & 100\% \\
Repeated variables & 8 & 100\% \\
Alternatives & 12 & 100\% \\
Structured patterns & 10 & 100\% \\
\midrule
\textbf{Total} & \textbf{54} & \textbf{100\%} \\
\bottomrule
\end{tabular}
\caption{Correctness validation results}
\end{table}

\subsection{Bytecode Characteristics}

Table~\ref{tab:bytecode_chars} shows instruction count and register usage for representative patterns.

\begin{table}[h]
\centering
\small
\begin{tabular}{lrr}
\toprule
\textbf{Pattern} & \textbf{Inst.} & \textbf{Regs.} \\
\midrule
\texttt{5} & 3 & 1 \\
\texttt{\_Integer} & 3 & 1 \\
\texttt{x\_Integer} & 6 & 3 \\
\texttt{f[x\_, x\_]} & 18 & 6 \\
\texttt{\_Real | \_Integer} & 12 & 1 \\
\texttt{f[g[x\_], y\_]} & 22 & 8 \\
\bottomrule
\end{tabular}
\caption{Bytecode characteristics}
\label{tab:bytecode_chars}
\end{table}

\textbf{Observations:}
\begin{itemize}
    \item Simple patterns compile to 3--6 instructions
    \item Instruction count scales linearly with pattern complexity
    \item Alternatives add ~4 instructions per branch
    \item Repeated variables add ~6 instructions for equality checking
\end{itemize}

\subsection{Execution Metrics}

Table~\ref{tab:exec_metrics} shows execution cycles for successful and failed matches.

\begin{table}[h]
\centering
\small
\begin{tabular}{lrr}
\toprule
\textbf{Pattern} & \textbf{Success} & \textbf{Failure} \\
\midrule
\texttt{5} & 3 & 2 \\
\texttt{\_Integer} & 3 & 2 \\
\texttt{x\_Integer} & 6 & 2 \\
\texttt{f[x\_, x\_]} & 22 & 17 \\
\texttt{\_Real | \_Integer} (1st) & 8 & --- \\
\texttt{\_Real | \_Integer} (2nd) & 14 & 8 \\
\bottomrule
\end{tabular}
\caption{Execution cycles}
\label{tab:exec_metrics}
\end{table}

\textbf{Key findings:}
\begin{itemize}
    \item Cycle count ≈ instruction count (minimal dispatch overhead)
    \item Failure is faster than success (no binding overhead)
    \item Backtracking adds ~6 cycles for state restoration
\end{itemize}

\subsection{When Is Compilation Beneficial?}

Compilation overhead is approximately 1--5ms per pattern. Break-even analysis:

\begin{itemize}
    \item \textbf{Simple patterns}: Break-even after ~100 executions
    \item \textbf{Complex patterns}: Break-even after ~10 executions
\end{itemize}

\textbf{Ideal use cases:}
\begin{itemize}
    \item Rule-based transformations (\texttt{ReplaceRepeated})
    \item Pattern-based function definitions called repeatedly
    \item Search over large expression databases
\end{itemize}

\textbf{Not beneficial for:}
\begin{itemize}
    \item Single-use patterns
    \item Runtime-constructed patterns
    \item Very simple literal comparisons
\end{itemize}

% ============================================================================
% 6. IMPLEMENTATION
% ============================================================================
\section{Implementation}

The implementation comprises approximately 3,900 lines of code split between C++ (compiler and VM core) and Wolfram Language (high-level API and paclet infrastructure). This section describes the system architecture, key components, and critical implementation decisions.

\subsection{Code Organization}

\begin{table}[h]
\centering
\small
\begin{tabular}{lrl}
\toprule
\textbf{Component} & \textbf{LOC} & \textbf{Language} \\
\midrule
Compiler & 850 & C++ \\
Virtual Machine & 720 & C++ \\
AST representation & 980 & C++ \\
LibraryLink integration & 350 & C++ \\
Expression wrappers & 350 & C++ \\
\midrule
Frontend API & 280 & WL \\
Backend integration & 150 & WL \\
Testing framework & 220 & WL \\
\midrule
\textbf{Total} & \textbf{3,900} & \\
\bottomrule
\end{tabular}
\caption{Code distribution by component}
\end{table}

\subsection{System Architecture}

The implementation follows a layered architecture with clear separation between host language integration, compilation, and execution:

\begin{enumerate}
    \item \textbf{Wolfram Language API layer}: Provides user-facing functions (\texttt{PatternMatcherExecute}, \texttt{CompilePatternToBytecode}) with pattern normalization, error handling, and result formatting.
    
    \item \textbf{LibraryLink bridge}: Manages C++ library loading, expression marshaling between Wolfram Language and C++ representations, and object lifetime through \texttt{ManagedLibraryExpressionID}.
    
    \item \textbf{Internal AST (MExpr)}: Provides efficient C++-native representation of Wolfram expressions, avoiding repeated LibraryLink calls during compilation. Supports literals (integer, real, string, symbol), normal expressions (head + arguments), and pattern constructs.
    
    \item \textbf{Pattern compiler}: Traverses MExpr AST, maintains lexical environment for variable tracking, generates bytecode with explicit register allocation, and manages label resolution for jumps.
    
    \item \textbf{Virtual machine}: Interprets bytecode through fetch-decode-execute loop, manages expression and integer register files, implements backtracking via choice point stack and trail, and collects execution metrics.
\end{enumerate}

\subsection{Key Components}

\subsubsection{Pattern Compiler}

The compiler (\texttt{CompilePatternToBytecode.cpp}, 850 LOC) implements recursive pattern traversal with several responsibilities:

\textbf{Lexical environment tracking}: Maintains a compile-time symbol table mapping pattern variable names to register assignments. When a variable appears multiple times (e.g., \texttt{f[x\_, x\_]}), the first occurrence allocates a register and emits \texttt{BIND}, while subsequent occurrences emit \texttt{EQ} instructions to verify equality.

\textbf{Register allocation}: Uses a simple infinite-register model where each distinct value gets a fresh register. Register \texttt{\%e0} is reserved by convention for the current match target. Arguments are decomposed into consecutive registers (\texttt{\%e1}, \texttt{\%e2}, etc.).

\textbf{Label management}: Forward jumps (from conditionals and alternatives) require two-pass label resolution: placeholder labels during code generation, followed by address patching once target locations are known.

\textbf{Alternative compilation}: Generates the TRY/RETRY/TRUST sequence by emitting \texttt{TRY label} for first alternative, \texttt{RETRY label} for middle alternatives, and \texttt{TRUST} for the final alternative, ensuring proper choice point lifecycle.

\subsubsection{Virtual Machine}

The VM (\texttt{VirtualMachine.cpp}, 720 LOC) executes bytecode through a standard interpreter loop with pattern-specific optimizations:

\textbf{Register files}: Maintains separate register files for expressions (\texttt{std::vector<Expr>}) and integers (\texttt{std::vector<mint>}). Expression registers hold Wolfram \texttt{Expr} objects, while integer registers cache frequently-used counts (argument counts, choice point depths) to avoid boxing overhead.

\textbf{Choice point stack}: Each choice point records saved program counter, register snapshot (shallow copy of register file), and trail checkpoint. Choice points are pushed by \texttt{TRY}, updated by \texttt{RETRY}, and popped by \texttt{TRUST} or successful completion.

\textbf{Trail}: Records variable bindings made during match attempts. On backtracking, the trail is unwound to restore registers to their pre-binding state. \textit{Optimization}: trailing is disabled when the choice point stack is empty (deterministic execution), avoiding unnecessary bookkeeping.

\textbf{Metrics collection}: Optionally tracks total instructions executed, cycles (including backtracking overhead), choice points created, backtrack events, and peak register usage. These metrics are exposed through the Wolfram Language API for introspection.

\subsubsection{Internal AST (MExpr)}

The MExpr representation (\texttt{AST/MExpr.cpp}, 980 LOC) provides a C++-native expression tree optimized for compilation:

\textbf{Polymorphic design}: Uses class hierarchy with virtual methods for pattern matching operations. Base class \texttt{MExpr} has derived types: \texttt{MExprLiteral} (atoms), \texttt{MExprNormal} (compound expressions), \texttt{MExprSymbol} (named entities).

\textbf{Pattern analysis}: Implements methods for detecting pattern constructs (\texttt{isBlank()}, \texttt{isNamedPattern()}, \texttt{isAlternatives()}), extracting pattern components (blank head, variable name, test function), and supporting compiler queries without string manipulation.

\textbf{Conversion}: Bidirectional conversion between Wolfram \texttt{Expr} (LibraryLink) and \texttt{MExpr} (internal). Conversion happens once at API boundary, then all compilation operates on MExpr.

\subsubsection{Paclet Interface}

The system is packaged as a Wolfram Language paclet exposing three core functions. \texttt{CompilePatternToBytecode[pattern]} compiles a pattern to an opaque bytecode object suitable for repeated execution. \texttt{PatternMatcherExecute[pattern, expr]} performs compilation and execution in one step, returning an association containing the match result (\texttt{True}/\texttt{False}), variable bindings, and execution metrics (instruction count, backtrack events). \texttt{DisassembleBytecode[bytecode]} provides human-readable instruction listings for debugging and analysis.

The API design enables amortized compilation costs through bytecode reuse:

\begin{lstlisting}[style=wolfram,numbers=none]
bc = CompilePatternToBytecode[f[x_, x_]]
results = Table[
  PatternMatcherExecute[bc, expr]["Result"],
  {expr, {f[1,1], f[2,3], f[5,5]}}
]
(* {True, False, True} *)
\end{lstlisting}

Execution metrics exposed through the API support the observability design principle (Section~3.1), enabling performance analysis and debugging of compiled patterns.

\subsubsection{LibraryLink Integration}

The bridge layer (\texttt{LibraryLink.cpp}, 350 LOC) handles Wolfram-C++ interaction:

\textbf{Managed objects}: Uses \texttt{ManagedLibraryExpressionID} to create opaque handles for C++ objects (compiled bytecode, VM instances) that can be passed between Wolfram Language and C++. Wolfram Language's reference counting triggers C++ destructors when objects are no longer referenced.

\textbf{Error propagation}: Maps C++ exceptions to Wolfram \texttt{Failure} objects with structured error information (error type, message, context). Ensures no C++ exceptions cross the LibraryLink boundary.

\textbf{Expression marshaling}: Implements efficient conversion of Wolfram expressions to MExpr representation. Uses LibraryLink's \texttt{MTensor}, \texttt{MNumericArray} interfaces for bulk data transfer when appropriate.

\subsection{Critical Design Decisions}

\textbf{Register-based over stack-based}: Eliminates explicit stack manipulation instructions, reducing average instruction count by 20-30\%. Makes data flow explicit in bytecode, simplifying analysis and debugging.

\textbf{Separate internal representation (MExpr)}: Avoids LibraryLink overhead during compilation (creating temporary Wolfram expressions for intermediate values). Provides type-safe pattern queries through C++ polymorphism rather than repeated \texttt{Head[]}, \texttt{Part[]} calls.

\textbf{Compile-time lexical environment}: Detects repeated variables during compilation, emitting different instruction sequences for first vs. subsequent occurrences. Eliminates need for runtime symbol tables during pattern matching.

\textbf{TRY/RETRY/TRUST protocol}: Adapted from Warren Abstract Machine, provides structured backtracking with explicit choice point lifecycle. \texttt{TRUST} optimization eliminates unnecessary choice point for final alternative.

\textbf{Conditional trailing}: Only trails variable bindings when choice points exist. In deterministic patterns (no alternatives), trailing overhead is completely eliminated, reducing execution cost by 15-25\%.

\textbf{Fused test-and-branch}: Instructions like \texttt{TEST\_HEAD\_JUMP} combine testing (head comparison) with conditional control flow (jump on failure) in a single opcode. Reduces instruction count and eliminates temporary boolean values.

\subsection{Instruction Encoding}
\label{sec:impl-encoding}

The instruction encoding balances implementation simplicity with the flexibility needed for pattern matching operations. This subsection details the concrete representation of bytecode instructions.

\subsubsection{Struct-Based Representation}

Instructions are represented as C++ structs rather than byte arrays. Each instruction contains:
\begin{itemize}
    \item \textbf{Opcode}: Enum value identifying the operation
    \item \textbf{Operands}: Variable-length vector of tagged unions
\end{itemize}

The struct definition is:
\begin{lstlisting}[language=C++,basicstyle=\ttfamily\small,numbers=none]
struct Instruction {
    Opcode opcode;
    std::vector<Operand> ops;
};
\end{lstlisting}

\textbf{Example:} The instruction \texttt{MATCH\_HEAD \%e0, Integer, L\_fail} from Section~\ref{sec:isa} is encoded as:
\begin{lstlisting}[language=C++,basicstyle=\ttfamily\small,numbers=none]
Instruction {
    opcode: MATCH_HEAD,
    ops: [ExprRegOp{0}, ImmExpr{Integer}, LabelOp{3}]
}
\end{lstlisting}

\subsubsection{Operand Type System}

Operands use \texttt{std::variant} to represent multiple value types in a type-safe manner:
\begin{lstlisting}[language=C++,basicstyle=\ttfamily\small,numbers=none]
using Operand = std::variant<
    std::monostate,  // No operand
    ExprRegOp,       // Expression register (E)
    BoolRegOp,       // Boolean register (B)
    LabelOp,         // Jump target (L)
    Ident,           // Variable name (string)
    ImmExpr,         // Immediate Expr constant (v)
    ImmMint          // Immediate integer (i)
>;
\end{lstlisting}

Each wrapper type (\texttt{ExprRegOp}, \texttt{BoolRegOp}, etc.) corresponds directly to the operand notation introduced in Section~\ref{sec:isa}: \texttt{E}, \texttt{B}, \texttt{L}, variable names, and immediate values. Wrapper types enable the variant to distinguish between different uses of the same underlying type—for example, \texttt{ExprRegOp\{5\}} versus \texttt{LabelOp\{5\}} both wrap \texttt{size\_t} but represent semantically distinct operands.

Type safety is enforced at compile time through \texttt{std::visit}. Operand type mismatches—such as using a boolean register where an expression register is required—are caught during bytecode generation rather than at runtime.

\subsubsection{Design Rationale}

This struct-based encoding prioritizes implementation clarity over space efficiency:

\textbf{Advantages:}
\begin{itemize}
    \item \textbf{No decoding overhead}: Interpreter accesses fields directly without parsing byte streams
    \item \textbf{Rich operand types}: Immediate operands can be full \texttt{Expr} objects (e.g., \texttt{Integer}, \texttt{Pi}) without serialization
    \item \textbf{Type safety}: C++ type system prevents operand misuse at compile time
    \item \textbf{Debuggability}: Memory dumps show readable structs rather than opaque byte sequences
    \item \textbf{Rapid prototyping}: No need to design encoding formats, bit packing, or alignment rules
\end{itemize}

\textbf{Disadvantages:}
\begin{itemize}
    \item \textbf{Memory overhead}: Each instruction requires $\sim$40-80 bytes (opcode + vector overhead + variant overhead) versus 1-8 bytes for byte-oriented encodings
    \item \textbf{Cache inefficiency}: Pointer indirection through \texttt{std::vector} reduces locality
    \item \textbf{No serialization}: Bytecode cannot be easily written to disk or transmitted
\end{itemize}

\subsubsection{Future: Byte-Oriented Encoding}

Production VMs (JVM, Python, Lua) use compact byte arrays with fixed-width or variable-length encodings. A future byte-oriented format for this VM might use:
\begin{itemize}
    \item 1 byte for opcode (supports up to 256 instructions)
    \item Variable operands: register indices as 1-byte offsets, labels as 2-byte relative offsets
    \item Immediate pool: Constants stored separately, referenced by index
\end{itemize}

This would reduce typical instruction size from $\sim$60 bytes to 2-5 bytes, improving cache locality and enabling bytecode serialization. However, it requires:
\begin{itemize}
    \item Operand decoding logic in the interpreter loop
    \item Immediate value pool management
    \item Label resolution to relative offsets
    \item Careful handling of \texttt{Expr} object lifetimes
\end{itemize}

The struct-based encoding serves current needs for a research prototype while leaving migration to byte-oriented formats as a well-defined optimization path.

\subsection{Engineering Challenges}

\textbf{Memory management across language boundary}: Wolfram expressions use reference counting, while C++ uses manual memory management. Required careful attention to ownership transfer and lifetime management to prevent leaks and dangling pointers.

\textbf{Expression equality semantics}: Wolfram Language's \texttt{SameQ} has subtle semantics (structural equality, attribute-aware comparison). Replicating exact semantics in C++ required careful study of edge cases.

\textbf{Pattern construct detection}: Distinguishing pattern syntax (\texttt{Blank[]}, \texttt{Pattern[]}) from normal expressions required building pattern analysis utilities that inspect head and structure without evaluating.

\textbf{Debugging bytecode execution}: Initial implementation had no visibility into VM state. Added comprehensive logging, single-step execution mode, and register inspection to diagnose compilation and execution bugs.

% ============================================================================
% 7. RELATED WORK
% ============================================================================
\section{Related Work}

\textbf{Warren Abstract Machine (WAM):} The WAM\cite{ait-kaci1999} pioneered structured backtracking for logic programming via choice points and trail. Our backtracking mechanism adapts WAM's TRY/RETRY/TRUST protocol to pattern matching.

\textbf{Lua VM:} The Lua virtual machine\cite{ierusalimschy2005} demonstrates the effectiveness of register-based architectures, influencing our decision to use explicit registers rather than a stack.

\textbf{TinyLisp:} Bendersky's TinyLisp shows how minimal instruction sets can express rich semantics, inspiring our focus on instruction set minimality.

\textbf{Wolfram Compiler:} The Wolfram Compiler\cite{wolfram-compiler} compiles high-level Wolfram Language to optimized native code, demonstrating the value of compilation in symbolic systems.

\textbf{Pattern matching compilation:} Maranget\cite{maranget2008} introduced decision tree compilation for pattern matching. We take a simpler direct compilation approach, prioritizing clarity over optimization.

\textbf{OCaml pattern matching:} OCaml compiles patterns to efficient decision trees with sharing. Our system focuses on explicit backtracking rather than optimization.

% ============================================================================
% 8. CONCLUSION
% ============================================================================
\section{Conclusion}

We have presented a register-based virtual machine for compiling and executing Wolfram Language patterns. The system demonstrates that pattern matching can be compiled to a minimal, well-structured instruction set (21 opcodes) with explicit backtracking control based on the Warren Abstract Machine.

Key achievements:
\begin{itemize}
    \item \textbf{Minimal instruction set}: 21 opcodes covering all core pattern constructs
    \item \textbf{Structured backtracking}: WAM-inspired protocol with choice points and trail
    \item \textbf{Semantic equivalence}: 100\% compatibility with native \texttt{MatchQ}
    \item \textbf{Practical API}: Complete paclet integration for Wolfram Language
    \item \textbf{Observability}: Exposure of execution metrics for analysis
\end{itemize}

\subsection{Limitations}

Current limitations include:

\begin{itemize}
    \item Compilation overhead makes single-use patterns inefficient
    \item Limited pattern feature coverage (~50\% of Wolfram Language patterns)
    \item No optimization passes (constant folding, dead code elimination)
    \item Register allocation not optimal (unlimited registers)
\end{itemize}

\subsection{Future Work}

Promising directions include:

\textbf{Extended pattern support:} Sequence patterns (\texttt{\_\_}), conditionals (\texttt{/;}), optional patterns, and orderless matching.

\textbf{Optimization passes:} Constant folding, dead code elimination, redundant test elimination, and register allocation.

\textbf{JIT compilation:} Compiling hot bytecode to native code for frequently executed patterns.

\textbf{Pattern analysis:} Static analysis to predict execution costs, detect overlapping patterns, and suggest optimizations.

\textbf{Bytecode caching:} Serializing bytecode for persistent storage and reuse across sessions.

\textbf{Pattern mining:} Analyzing large codebases to identify common pattern structures and optimization opportunities.

The virtual machine provides a foundation for exploring pattern matching as an explicit computational model, enabling new analysis techniques and optimization strategies unavailable in purely interpretive approaches.

% ============================================================================
% ACKNOWLEDGMENTS
% ============================================================================
\section*{Acknowledgments}

We thank the reviewers for their insightful comments and suggestions. This work was supported by the Universidad Nacional Autónoma de México.

% ============================================================================
% REFERENCES
% ============================================================================
\begin{thebibliography}{9}

\bibitem{ait-kaci1999}
Hassan Aït-Kaci.
\textit{Warren's Abstract Machine: A Tutorial Reconstruction}.
MIT Press, 1999.

\bibitem{fang2016}
Ruijie Fang, Siqi Liu.
A Performance Survey on Stack-based and Register-based Virtual Machines.
\textit{arXiv preprint arXiv:1611.00467}, 2016.

\bibitem{ierusalimschy2005}
Roberto Ierusalimschy, Luiz Henrique de Figueiredo, Waldemar Celes.
The Implementation of Lua 5.0.
\textit{Journal of Universal Computer Science}, vol. 11, no. 7, 2005.

\bibitem{maranget2008}
Luc Maranget.
Compiling Pattern Matching to Good Decision Trees.
\textit{ML Workshop}, 2008.

\bibitem{wolfram-compiler}
Abdul Dakkak, Tom Wickham-Jones.
The Wolfram Compiler.
\textit{CGO}, 2020.

\end{thebibliography}

\end{document}
